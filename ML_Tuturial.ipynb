{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_gxYLaTb8J7"
      },
      "source": [
        "* 기계학습은 1개의이상의 독립변수 $X$ 집합을 사용하여 종속변수 $y$ 를 예측하는 문제임\n",
        "\n",
        "> 약인공지능(weak AI) 에 해당되며 특정분야에 한정하여 일을 처리하도록 설계됨\n",
        "\n",
        "* 기계학습에서는 하나의 데이터, 하나의 행을 샘플(sample)이라고 함\n",
        "* $y$ 는 카테고리, 범주 또는 클래스라고 함\n",
        "\n",
        "* 기계학습 문제는 분류와 회귀 문제로 나누어질 수 있음\n",
        "> 분류는 범주형 레이블을 예측하는 것이고 회귀는 연속된 값을 예측하는 것임\n",
        "\n",
        "\n",
        "* **SVM(Support Vector Machine)**은 데이터 분석 중 분류에 이용되며 지도학습 방식의 모델\n",
        "> 다중클래스 문제, 입력변수에 대한 두개 이상의 정해진 선택지 중에서 답을 분류하는 문제, 에 활용함 \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gK_2Q2sPr4Pj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm\n",
        "from sklearn.datasets.samples_generator import make_blobs\n",
        "\n",
        "# make_blobs() 함수를 이용해 2종류의 총 40개의 샘플 데이터를 생성\n",
        "X, y = make_blobs(n_samples=40, centers=2, random_state=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GDJjnuVYb6O"
      },
      "source": [
        "분류을 위한 샘플은 독립변수 $X$ 와 종속변수 $y$ 로 이루어지며, 학습자료에서 $y$ 는 레이블(분류값)을 을 의미함 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "505KcFLeZ2pY"
      },
      "outputs": [],
      "source": [
        "print (f\"독립변수 {X[0]}, 종속변수 {y[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rm4SuAkpXYF1"
      },
      "outputs": [],
      "source": [
        "# SVM은 선형 분류와 비선형 분류를 지원\n",
        "# clf = svm.SVC(kernel='linear') \n",
        "clf = svm.SVC(kernel='rbf') \n",
        "clf.fit(X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxitv-KEXah3"
      },
      "outputs": [],
      "source": [
        "# 학습된 SVM 모델을 통해 데이터 (3,4)를 분류\n",
        "newData = [[3,4]]\n",
        "print(clf.predict(newData))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1hIxo7NdOJe"
      },
      "source": [
        "샘플 데이터와 초평면(Hyper-Plane), 지지벡터(Support Vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EfThJnqXk_3"
      },
      "outputs": [],
      "source": [
        "# 샘플 데이터 표현\n",
        "plt.scatter(X[:,0], X[:,1], c=y, s=30, cmap=plt.cm.Paired)\n",
        "# 초평면(Hyper-Plane) 표현\n",
        "ax = plt.gca()\n",
        "xlim = ax.get_xlim()\n",
        "ylim = ax.get_ylim()\n",
        "xx = np.linspace(xlim[0], xlim[1], 30)\n",
        "yy = np.linspace(ylim[0], ylim[1], 30)\n",
        "YY, XX = np.meshgrid(yy, xx)\n",
        "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
        "Z = clf.decision_function(xy).reshape(XX.shape)\n",
        "ax.contour(XX, YY, Z, colors='k', levels=[-1,0,1], alpha=0.5, linestyles=['--', '-', '--'])\n",
        "# 지지벡터(Support Vector) 표현\n",
        "ax.scatter(clf.support_vectors_[:,0], clf.support_vectors_[:,1], s=60, facecolors='r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crfuKX6jNlzI"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn import datasets\n",
        "# Standard scientific Python imports\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
        "for ax, image, label in zip(axes, digits.images, digits.target):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
        "    ax.set_title(\"Training: %i\" % label)\n",
        "\n",
        "# step-1: creating model class object \n",
        "model = SVC()\n",
        " \n",
        "\n",
        "# step-2: fitting training data\n",
        "model.fit(digits.data, digits.target)\n",
        "\n",
        "# step-3: using model to predict target class\n",
        "result = list(model.predict(digits.data[:4]))\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JByw1YlYRor4"
      },
      "outputs": [],
      "source": [
        "print (f\"The classification result of digits = {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ4dyac7c4e3"
      },
      "source": [
        "* 이미지 데이터셋을 사용한 글자 식별 (분류)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEQqCLDESARH"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "# Standard scientific Python imports\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "# flatten the images\n",
        "n_samples = len(digits.images)\n",
        "data = digits.images.reshape((n_samples, -1))\n",
        "\n",
        "# Create a classifier: a support vector classifier\n",
        "clf = SVC(gamma=0.001)\n",
        "\n",
        "# Split data into 50% train and 50% test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data, digits.target, test_size=0.5, shuffle=False\n",
        ")\n",
        "\n",
        "# Learn the digits on the train subset\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the value of the digit on the test subset\n",
        "predicted = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAU4hBXSSUuE"
      },
      "outputs": [],
      "source": [
        "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
        "for ax, image, prediction in zip(axes, X_test, predicted):\n",
        "    ax.set_axis_off()\n",
        "    image = image.reshape(8, 8)\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
        "    ax.set_title(f\"Prediction: {prediction}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zNv04QBesPF"
      },
      "source": [
        "* 정확도(accuracy), 전체데이터 중에서 정확히 분류된 데이터의 비율 \n",
        "* 정밀도(precision), 해당 데이터 중 모델이 올바르게 검출된 데이터 비율 ($tp$ / ($tp$ + $fp$))\n",
        "* 재현율(recall), 실제값이 정답인 데이터 전체 개수에 대한 정답 비율 ($tp$ / ($tp$ + $fn$) \n",
        "정답자료 중 얼마나 정답이 예측되었는가)\n",
        "* 지지(support),클래스 별 정답 비율 \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wdv2uMNNSbG5"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "print(\n",
        "    f\"Classification report for classifier {clf}:\\n\"\n",
        "    f\"{metrics.classification_report(y_test, predicted)}\\n\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz1U7Wsode9Q"
      },
      "source": [
        "OneClassSVM 을 사용한 이상 검출하기\n",
        "* 이진분류(binary classification) \n",
        "* 정상메일과 스팸메일 판단"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJpHFnbbdieF"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.datasets import make_blobs\n",
        "from numpy import quantile, where, random\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sU3xk5CLdjok"
      },
      "outputs": [],
      "source": [
        "random.seed(13)\n",
        "x, _ = make_blobs(n_samples=200, centers=1, cluster_std=.3, center_box=(8, 8))\n",
        "\n",
        "plt.scatter(x[:,0], x[:,1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TSVTBesdnpH"
      },
      "outputs": [],
      "source": [
        "svm = OneClassSVM(kernel='rbf', gamma=0.001, nu=0.03)\n",
        "print(svm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y28gnWZVdrC2"
      },
      "outputs": [],
      "source": [
        "svm.fit(x)\n",
        "pred = svm.predict(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5IBygWGduGI"
      },
      "outputs": [],
      "source": [
        "anom_index = where(pred==-1)\n",
        "values = x[anom_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEUb4cfndxro"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x[:,0], x[:,1])\n",
        "plt.scatter(values[:,0], values[:,1], color='r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vVCdLwPePOW"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-KSTOLQd0Nc"
      },
      "outputs": [],
      "source": [
        "svm = OneClassSVM(kernel='rbf', gamma=0.001, nu=0.02)\n",
        "print(svm)\n",
        "\n",
        "svm.fit(x)\n",
        "pred = svm.predict(x)\n",
        "anom_index = where(pred==-1)\n",
        "values = x[anom_index]\n",
        "\n",
        "plt.scatter(x[:,0], x[:,1])\n",
        "plt.scatter(values[:,0], values[:,1], color='r')\n",
        "plt.show()\n",
        "\n",
        "svm = OneClassSVM(kernel='rbf', gamma=0.001, nu=0.02)\n",
        "print(svm)\n",
        "\n",
        "pred = svm.fit_predict(x)\n",
        "scores = svm.score_samples(x)\n",
        "\n",
        "thresh = quantile(scores, 0.03)\n",
        "print(thresh)\n",
        "index = where(scores<=thresh)\n",
        "values = x[index]\n",
        "\n",
        "plt.scatter(x[:,0], x[:,1])\n",
        "plt.scatter(values[:,0], values[:,1], color='r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVlygjMJhLi5"
      },
      "source": [
        "* DBSCAN (Density-Based Spatial Clustering of Applications with Noise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LMg_AKuhDpv"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.datasets import make_blobs\n",
        "from numpy import random, where\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "random.seed(7)\n",
        "x, _ = make_blobs(n_samples=200, centers=1, cluster_std=.3, center_box=(20, 5))\n",
        "\n",
        "plt.scatter(x[:,0], x[:,1])\n",
        "plt.show()\n",
        "\n",
        "dbscan = DBSCAN(eps = 0.28, min_samples = 20)\n",
        "print(dbscan)\n",
        "\n",
        "pred = dbscan.fit_predict(x)\n",
        "anom_index = where(pred == -1)\n",
        "values = x[anom_index]\n",
        "\n",
        "plt.scatter(x[:,0], x[:,1])\n",
        "plt.scatter(values[:,0], values[:,1], color='r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBPVvCQfhsQh"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from numpy import sqrt, array, random, argsort\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.datasets import load_boston\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "random.seed(123)\n",
        "def makeData(N):\n",
        "\tx = []\n",
        "\tfor i in range(N):\n",
        "\t\ta = i/1000 + random.uniform(-3, 2)\n",
        "\t\tr = random.uniform(-5, 10)\n",
        "\t\tif(r >= 9.9):\n",
        "\t\t\tr = r + 10\n",
        "\t\telif(r<(-4.8)):\n",
        "\t\t\tr = r +(- 10)\t\t\t\n",
        "\t\tx.append([a + r])\t\n",
        "\treturn array(x)\n",
        "\n",
        "x = makeData(500)\n",
        "x_ax = range(500)\n",
        "plt.plot(x_ax, x)\n",
        "plt.show()\n",
        "\n",
        "x = scale(x)\n",
        "kmeans = KMeans(n_clusters = 1).fit(x)\n",
        "print(kmeans)\n",
        "\n",
        "center = kmeans.cluster_centers_\n",
        "print(center)\n",
        "\n",
        "distance = sqrt((x - center)**2)\n",
        "order_index = argsort(distance, axis = 0)\n",
        "indexes = order_index[-5:]\n",
        "values = x[indexes]\n",
        "\n",
        "plt.plot(x_ax, x)\n",
        "plt.scatter(indexes, values, color='r')\n",
        "plt.show()\n",
        "\n",
        "# Boston housing dataset case\n",
        "boston = load_boston()\n",
        "y =  boston.target\n",
        "y = y.reshape(y.shape[0], 1)\n",
        "y = scale(y)\n",
        "\n",
        "kmeans = KMeans(n_clusters = 1).fit(y)\n",
        "print(kmeans)\n",
        "\n",
        "center = kmeans.cluster_centers_\n",
        "print(center)\n",
        "\n",
        "distance = sqrt((y - center)**2)\n",
        "order_index = argsort(distance, axis = 0)\n",
        "indexes = order_index[-10:]\n",
        "values = y[indexes]\n",
        "\n",
        "x_ax = range(y.shape[0])\n",
        "plt.plot(x_ax, y)\n",
        "plt.scatter(indexes,values, color='r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qL4Ddu7viRgU"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.datasets import make_blobs\n",
        "from numpy import quantile, where, random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "random.seed(1)\n",
        "x, _ = make_blobs(n_samples=200, centers=1, cluster_std=.3, center_box=(10,10))\n",
        "\n",
        "plt.scatter(x[:,0], x[:,1])\n",
        "plt.show()\n",
        "\n",
        "lof = LocalOutlierFactor(n_neighbors=20, contamination=.03)\n",
        "print(thresh)  \n",
        " \n",
        "y_pred = lof.fit_predict(x)\n",
        "\n",
        "lofs_index=where(y_pred==-1)\n",
        "values = x[lofs_index]\n",
        "\n",
        "plt.scatter(x[:,0], x[:,1])\n",
        "plt.scatter(values[:,0],values[:,1], color='r')\n",
        "plt.show()\n",
        "\n",
        "model = LocalOutlierFactor(n_neighbors=20) \n",
        "print(model)  \n",
        "model.fit_predict(x) \n",
        " \n",
        "lof = model.negative_outlier_factor_\n",
        "thresh = quantile(lof, .03)\n",
        "print(thresh) \n",
        " \n",
        "index = where(lof<=thresh)\n",
        "values = x[index]\n",
        "\n",
        "plt.scatter(x[:,0], x[:,1])\n",
        "plt.scatter(values[:,0],values[:,1], color='r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82u2mozllprf"
      },
      "source": [
        "* Naive Bayesian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4kkc1TDlTd9"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "print(type(iris))\n",
        "# Bunch 클래스: {'data': [], 'target': []}으로 이루어진 dict와 비슷한 클래스\n",
        "# data: 특성(변수)들. n차원 공간의 점(point)\n",
        "# target: 레이블(분류 클래스)\n",
        "# print(iris)\n",
        "print('data shape:', iris.data.shape)\n",
        "print('iris target:', iris.target_names)\n",
        "print('iris features:', iris.feature_names)\n",
        "\n",
        "X = iris.data # 데이터(특성, 변수)\n",
        "print('type X:', type(X))\n",
        "print(X[:5])\n",
        "y = iris.target # 분류 클래스(레이블)\n",
        "print('type y:', type(y))\n",
        "print(y[:5])\n",
        "\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "# return_X_y=True: numpy.ndarray들의 튜플(data, target)을 리턴\n",
        "# return_X_y=False(기본값): Bunch 클래스 타입을 리턴\n",
        "\n",
        "# 데이터 세트를 학습(train)/검증(test) 세트로 나눔.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# 데이터들 변환(스케일링)\n",
        "scaler = StandardScaler() # 생성자 호출 - 변환기 객체 생성\n",
        "scaler.fit(X_train, y_train) # 학습 데이터의 평균과 표준 편차를 데이터 변환할 때 이용하기 위해서\n",
        "X_train_transformed = scaler.transform(X_train) # 학습 데이터 세트 변환\n",
        "\n",
        "X_test_transformed = scaler.transform(X_test) # 테스트 데이터 세트 변환\n",
        "\n",
        "# 머신 러닝 모델 선택 - Naive Bayes\n",
        "gnb = GaussianNB() # Gaussian Naive Bayes 모델 선택 - 연속형 자료\n",
        "gnb.fit(X_train_transformed, y_train) # 모델 학습\n",
        "y_pred = gnb.predict(X_test_transformed) # 예측\n",
        "\n",
        "# 성능 측정\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "53f80ada611156878e847d16745a65a3fa62c5f82ffb779816be8fdb63764b0e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
